# agents/search_agent.py

import os
from dotenv import load_dotenv
from typing import TypedDict, List, Dict, Any

from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from langchain_upstage import UpstageEmbeddings

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë²¡í„° DB ê²½ë¡œ
CHROMA_PATH = "chroma_db"
EMBEDDING_MODEL = "solar-embedding-1-large"


# ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì •ì˜
class SearchState(TypedDict):
    """ê²€ìƒ‰ Agentì˜ ìƒíƒœ"""
    question: str
    intent: str
    document_type: str | None
    urgency: str
    search_results: List[Document]
    templates: List[Document]
    examples: List[Document]
    related: List[Document]


class SearchAgent:
    """ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” Agent"""
    
    def __init__(self, vectorstore_path: str = None):
        """
        Args:
            vectorstore_path: Chroma DB ê²½ë¡œ (Noneì´ë©´ ìë™ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ìŒ)
        """
        # ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ chroma_db ì‚¬ìš©
        if vectorstore_path is None:
            # í˜„ì¬ íŒŒì¼(search_agent.py)ì˜ ìœ„ì¹˜ì—ì„œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(current_dir)  # agents/ -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
            vectorstore_path = os.path.join(project_root, "chroma_db")
        
        # ì„ë² ë”© í•¨ìˆ˜
        self.embedding_function = UpstageEmbeddings(model=EMBEDDING_MODEL)
        
        # Chroma DB ë¡œë“œ
        if os.path.exists(vectorstore_path):
            self.vectorstore = Chroma(
                persist_directory=vectorstore_path,
                embedding_function=self.embedding_function
            )
            print(f"âœ… ë²¡í„° DB ë¡œë“œ ì™„ë£Œ: {vectorstore_path}")
        else:
            print(f"âš ï¸  ë²¡í„° DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vectorstore_path}")
            self.vectorstore = None
    
    def _classify_documents(self, docs: List[Document]) -> Dict[str, List[Document]]:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í…œí”Œë¦¿, ì˜ˆì‹œ, ê´€ë ¨ ë¬¸ì„œë¡œ ë¶„ë¥˜"""
        templates = []
        examples = []
        related = []
        
        for doc in docs:
            source = doc.metadata.get("source", "").lower()
            
            if "í…œí”Œë¦¿" in source or "ì–‘ì‹" in source or "template" in source:
                templates.append(doc)
            elif "ì˜ˆì‹œ" in source or "ì‚¬ë¡€" in source or "example" in source:
                examples.append(doc)
            else:
                related.append(doc)
        
        return {
            "templates": templates,
            "examples": examples,
            "related": related
        }
    
    def _apply_filters(self, docs: List[Document], filters: Dict[str, Any]) -> List[Document]:
        """ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©"""
        filtered_docs = []
        
        for doc in docs:
            if filters.get("document_type"):
                doc_type = doc.metadata.get("document_type", "")
                source = doc.metadata.get("source", "")
                if (filters["document_type"].lower() not in doc_type.lower() and 
                    filters["document_type"].lower() not in source.lower()):
                    continue
            
            filtered_docs.append(doc)
        
        return filtered_docs if filtered_docs else docs
    
    def search_with_metadata(self, state: SearchState) -> SearchState:
        """ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰"""
        question = state["question"]
        intent = state["intent"]
        document_type = state.get("document_type")
        urgency = state.get("urgency", "ë³´í†µ")
        
        print(f"\nğŸ” ê²€ìƒ‰ Agent ì‘ë™: '{question}'")
        print(f"   ì˜ë„: {intent}, ë¬¸ì„œìœ í˜•: {document_type}, ê¸´ê¸‰ë„: {urgency}")
        
        if not self.vectorstore:
            print("   âŒ ë²¡í„° DBë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {
                **state,
                "search_results": [],
                "templates": [],
                "examples": [],
                "related": []
            }
        
        try:
            # 1. ë²¡í„° ê²€ìƒ‰
            search_results = self.vectorstore.similarity_search(question, k=10)
            print(f"   ğŸ“¦ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ë¬¸ì„œ")
            
            # 2. ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©
            filters = {
                "document_type": document_type,
                "urgency": urgency
            }
            filtered_results = self._apply_filters(search_results, filters)
            print(f"   ğŸ¯ í•„í„° ì ìš© í›„: {len(filtered_results)}ê°œ ë¬¸ì„œ")
            
            # 3. ë¬¸ì„œ ë¶„ë¥˜
            classified = self._classify_documents(filtered_results)
            
            print(f"   ğŸ“„ í…œí”Œë¦¿: {len(classified['templates'])}ê°œ")
            print(f"   ğŸ’¡ ì˜ˆì‹œ: {len(classified['examples'])}ê°œ")
            print(f"   ğŸ”— ê´€ë ¨ ë¬¸ì„œ: {len(classified['related'])}ê°œ")
            
            # 4. ìƒíƒœ ì—…ë°ì´íŠ¸
            new_state = {
                **state,
                "search_results": filtered_results[:5],
                "templates": classified["templates"][:3],
                "examples": classified["examples"][:3],
                "related": classified["related"][:3]
            }
            
            print(f"   âœ… ê²€ìƒ‰ ì™„ë£Œ")
            return new_state
            
        except Exception as e:
            print(f"   âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return {
                **state,
                "search_results": [],
                "templates": [],
                "examples": [],
                "related": []
            }


# --- í…ŒìŠ¤íŠ¸ ì½”ë“œ ---
if __name__ == "__main__":
    search_agent = SearchAgent()
    
    test_states = [
        {
            "question": "ì¶œì¥ì‹ ì²­ì„œ ì–´ë–»ê²Œ ì‘ì„±í•˜ë‚˜ìš”?",
            "intent": "í…œí”Œë¦¿_ì°¾ê¸°",
            "document_type": "ì¶œì¥ì‹ ì²­ì„œ",
            "urgency": "ë³´í†µ",
            "search_results": [],
            "templates": [],
            "examples": [],
            "related": []
        }
    ]
    
    print("=" * 60)
    print("SearchAgent í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for i, test_state in enumerate(test_states, 1):
        print(f"\n[í…ŒìŠ¤íŠ¸ {i}]")
        result_state = search_agent.search_with_metadata(test_state)
        
        print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"  - ê²€ìƒ‰ ê²°ê³¼: {len(result_state.get('search_results', []))}ê°œ")
        print(f"  - í…œí”Œë¦¿: {len(result_state.get('templates', []))}ê°œ")
        print(f"  - ì˜ˆì‹œ: {len(result_state.get('examples', []))}ê°œ")
        print(f"  - ê´€ë ¨: {len(result_state.get('related', []))}ê°œ")
        
        if result_state.get('templates'):
            print(f"\n  í…œí”Œë¦¿ ë¬¸ì„œ:")
            for doc in result_state['templates']:
                print(f"    - {doc.metadata.get('source', 'Unknown')}")
        
        print("-" * 60)
    
    print("\nâœ¨ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")